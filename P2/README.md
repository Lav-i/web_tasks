# 知乎爬虫

描述：用于爬取在某一 ~~钓鱼贴~~ 问题下所有 ~~咬钩~~ 回答者的图片

## 爬虫v3.0 
实现于2017年7月3日

### 1.目前状态：
已经能够爬取所有回答者的图片  
新增计时功能，经测试，爬取1500张照片耗时约60s，效率提高了近一倍  
运行方法：直接运行zhihu.py  
问题抛出：知乎是否存在反爬虫机制，爬取速度过快是否会被反爬虫机制拦截

### 2.所用到的库文件：
> * requests
> * re
> * os
> * urllib
> * time
> * threading
> * BeautifulSoup

### 3.目前需要攻克的问题：
- [ ] 反反爬虫机制
- [x] 多线程调度
- [x] 页面动态加载
- [ ] ~~ajax网页异步更新~~
- [x] 静态网页下载
- [x] 网页源码解析
- [x] 下载保存图片

## 爬虫v2.0 
实现于2017年7月2日

### 1.目前状态：
已经能够爬取所有回答者的图片  
运行方法：直接运行zhihu.py  
不足：经测试，爬取1500张照片耗时约100s，目标网页共计3千余个回答，照片数大概1万张以上，耗时非常长  
改进：尝试使用多线程调度，提高爬虫效率  
问题抛出：知乎是否存在反爬虫机制，爬取速度过快是否会被反爬虫机制拦截 

*思路纠正：
想要获取所有回答，不应该模拟滑轮滚动，而是想办法修改偏移量以及每页最大显示数*

### 2.所用到的第三方库：
> * urllib
> * BeautifulSoup4
> * requests

### 3.目前需要攻克的问题：
- [ ] 反反爬虫机制
- [ ] 多线程调度
- [x] 页面动态加载
- [ ] ~~ajax网页异步更新~~
- [x] 静态网页下载
- [x] 网页源码解析
- [x] 下载保存图片

----------

## 爬虫v1.0 
实现于2017年6月27日

### 1.目前状态：
目前仅能适用于静态网页的爬取

### 2.所用到的第三方库：
> * urllib
> * BeautifulSoup4
> * requests

### 3.目前需要攻克的问题：
- [ ] 页面动态加载
- [ ] ajax网页异步更新
- [x] 静态网页下载
- [x] 网页源码解析
- [x] 下载保存图片